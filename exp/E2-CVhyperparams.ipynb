{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597763679543",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2: Cross Validation for Hyperparameters of Uninformed Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from snorkel.labeling.model import LabelModel\n",
    "import numpy as np \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = None\n",
    "n_folds = 5\n",
    "metrics = [\"accuracy\", \"f1\", \"coverage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to experiment with\n",
    "n_epochs = [100, 500, 1000, 5000]\n",
    "lr = 10 ** (-1 * np.arange(1, 6, dtype=float))\n",
    "l2 = [0.0, 0.01, 0.1]\n",
    "optimizer = [\"sgd\",\"adam\",\"adamax\"]\n",
    "lr_scheduler = [\"constant\",\"linear\",\"exponential\",\"step\"]\n",
    "\n",
    "h_params_all = list( itertools.product(n_epochs, lr, optimizer, lr_scheduler) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant parts of label matrix\n",
    "lf_subset = list(range(57)) \n",
    "L_data = np.copy(L_alarms[:,lf_subset])\n",
    "Y_data = alarms_df.true_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = np.zeros((len(list(h_params_all)), len(metrics)))\n",
    "\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "for train_idx, test_idx in kf.split(L_data):\n",
    "    # Define training dataset\n",
    "    L_train = L_data[train_idx]\n",
    "    Y_train = Y_data[train_idx]\n",
    "    # Define test dataset\n",
    "    L_test = L_data[test_idx]\n",
    "    Y_test = Y_data[test_idx]\n",
    "\n",
    "    for i, h_params in enumerate(h_params_all):\n",
    "        # Fit a Label Model\n",
    "        l_model = LabelModel(cardinality=2, verbose=True)\n",
    "        l_model.fit(L_train, n_epochs=h_params[0], lr=h_params[1], optimizer=h_params[2], lr_scheduler=h_params[3])\n",
    "\n",
    "        # Evaluate model on test data\n",
    "        scores = l_model.score(L_test, Y_test, metrics=metrics)\n",
    "        cv_results[i,:] = cv_results[i,:] + list(scores.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the metrics\n",
    "cv_results /= n_folds\n",
    "print(cv_results)"
   ]
  }
 ]
}