{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5: Iteratively find Dependencies between LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from Our_Monitors.CD_Monitor import CDM\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "from random import sample\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the analysis\n",
    "num_iters = 5\n",
    "sample_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using original LFs in analysis\n",
    "lf_subset = list(range(57)) \n",
    "L_data = np.copy(L_alarms[:,lf_subset])\n",
    "Y_data = alarms_df.true_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(num_iters):\n",
    "    print(\"-- Iteration \", iter + 1, \"--\")\n",
    "\n",
    "    # Split into train and development set\n",
    "    L_train, L_dev, Y_train, Y_dev = train_test_split(L_data, Y_data, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    # Get edges of dependency graph from Conditional Dependency Monitor (CDM)\n",
    "    start = time()\n",
    "    deps = CDM(L_dev, Y_dev, k=2, sig=0.05, policy=\"old\", verbose=False)\n",
    "    print(\"CDM runtime: \", time() - start)\n",
    "    print(\"Num deps: \", len(deps))\n",
    "\n",
    "    # Generate graph from dependencies and find the maximum independent sets\n",
    "    G = ig.Graph()\n",
    "    G.add_vertices(L_data.shape[1])\n",
    "    G.add_edges(deps)\n",
    "    max_indep_sets = G.largest_independent_vertex_sets()\n",
    "    print(\"Num max independent sets: \", len(max_indep_sets))\n",
    "    print(\"Size max independent sets: \", len(max_indep_sets[0]))\n",
    "\n",
    "    # Dont iterate if there are no dependencies to consider in the next iteration\n",
    "    if len(deps) == 0:\n",
    "        break\n",
    "\n",
    "    # Update L_data (equivalent to defining a new LF per MIS, then applying them to the previous L_data)\n",
    "    print(\"updating L_data...\")\n",
    "    \n",
    "    if sample_size > 0:\n",
    "        print(\"sampling \", sample_size, \"of the MISs...\")\n",
    "        max_indep_sets = sample(max_indep_sets, sample_size)\n",
    "\n",
    "    print(\"LFs covered: \",  set.union( *[set(mis) for mis in max_indep_sets] )) \n",
    "\n",
    "    L_data_new = np.zeros((L_data.shape[0],len(max_indep_sets)))\n",
    "\n",
    "    for i, mis in enumerate(max_indep_sets):\n",
    "        mis = list(mis)     # mis is a tuple, converting to list\n",
    "        l_model = LabelModel(cardinality=2, verbose=True)\n",
    "        l_model.fit(L_train[:,mis], seed=SEED)\n",
    "        L_data_new[:,i] = l_model.predict(L_data[:,mis])\n",
    "\n",
    "    L_data = L_data_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart_alarm_env",
   "language": "python",
   "name": "smart_alarm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}