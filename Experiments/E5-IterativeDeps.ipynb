{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5: Iteratively find Dependencies between LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from Our_Monitors.CDGA_Monitor import CDGAM\n",
    "from snorkel.labeling import labeling_function, LFApplier\n",
    "from snorkel.labeling.model.label_model import LabelModel\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lf(id, mis, l_model):\n",
    "    @labeling_function(name=\"lf\" + str(id))\n",
    "    def lf(x):\n",
    "        return l_model.predict( np.asarray( [x[mis]] ) )[0]\n",
    "\n",
    "    return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_subset = list(range(57))     # only using original LFs\n",
    "lfs_iter = np.asarray(lfs)[lf_subset]\n",
    "L_data = np.copy(L_alarms[:,lf_subset])\n",
    "num_iters = 5\n",
    "\n",
    "for iter in range(num_iters):\n",
    "    print(\"-- Iteration \", iter + 1, \"--\")\n",
    "\n",
    "    # Apply lfs_iter to the alarms data\n",
    "    if iter != 0:\n",
    "        applier = LFApplier(lfs_iter)\n",
    "        L_data = applier.apply(alarms_data, progress_bar=True, fault_tolerant=True)\n",
    "\n",
    "    # Split into train and development set\n",
    "    L_train, L_dev, Y_train, Y_dev = train_test_split(L_data, alarms_df.true_label.values, test_size=0.2, random_state=SEED)\n",
    "\n",
    "    # Get edges of dependency graph from Conditional Dependency Monitor (CDM)\n",
    "    deps = CDGAM(L_dev, k=2, sig=0.05, policy='new', verbose=False, return_more_info=False)\n",
    "    print(\"Num deps: \", len(deps))\n",
    "\n",
    "    # Generate graph from dependencies and find the maximum independent sets\n",
    "    G = ig.Graph()\n",
    "    G.add_vertices(len(lfs_iter))\n",
    "    G.add_edges(deps)\n",
    "    max_indep_sets = G.largest_independent_vertex_sets()\n",
    "    print(\"Num max independent sets: \", len(max_indep_sets))\n",
    "    print(\"Size max independent sets: \", len(max_indep_sets[0]))\n",
    "\n",
    "    # Stop iterating if no dependencies to consider\n",
    "    if len(deps) == 0:\n",
    "        break\n",
    "\n",
    "    # Define a labeling function for each maximum independent set\n",
    "    print(\"creating new LFs...\")\n",
    "    new_lfs_iter = []\n",
    "    for i, mis in enumerate(max_indep_sets):\n",
    "        mis = list(mis)     # mis is a tuple, converting to list\n",
    "        l_model = LabelModel(cardinality=2, verbose=True)\n",
    "        l_model.fit(L_train[:,mis], seed=SEED)\n",
    "        new_lfs_iter.append( make_lf(i, mis, l_model) )\n",
    "\n",
    "    # Update parameters\n",
    "    lfs_iter = new_lfs_iter\n",
    "    alarms_data = np.copy(L_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
